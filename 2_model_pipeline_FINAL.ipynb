{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9115d167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 0. IMPORTS & PARAMETERS ---\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# On garde uniquement les bibliothèques de calcul (pas de graphique)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "\n",
    "# --- CONFIGURATION OPTIMISÉE ---\n",
    "DEBUG = False          # Mettre à False pour le rendu final (tout le dataset)\n",
    "MAX_ROWS = 5000        # (Ignoré si DEBUG = False)\n",
    "N_ESTIMATORS = 100     # Plus d'arbres pour la forêt\n",
    "\n",
    "# Création des dossiers\n",
    "os.makedirs(\"splits\", exist_ok=True)\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "# os.makedirs(\"figures\", exist_ok=True) # Plus besoin de dossier figures\n",
    "\n",
    "# Mapping\n",
    "label_map = {\n",
    "    0: 'Sadness', 1: 'Joy', 2: 'Love', \n",
    "    3: 'Anger', 4: 'Fear', 5: 'Surprise'\n",
    "}\n",
    "\n",
    "# --- 1. CHARGEMENT ---\n",
    "print(\" Loading Data...\")\n",
    "df = pd.read_csv(\"emotions_cleaned_features.csv\").dropna(subset=['text', 'label'])\n",
    "\n",
    "if DEBUG and len(df) > MAX_ROWS:\n",
    "    df = df.sample(n=MAX_ROWS, random_state=42).reset_index(drop=True)\n",
    "    print(f\" DEBUG MODE: Reduced to {MAX_ROWS} rows.\")\n",
    "else:\n",
    "    print(f\" FULL MODE: Training on {len(df)} rows.\")\n",
    "\n",
    "# --- 2. SPLIT RIGOUREUX (70/15/15) ---\n",
    "X = df['text']\n",
    "y = df['label'] \n",
    "\n",
    "print(\"✂️ Splitting Data (70% Train / 15% Val / 15% Test)...\")\n",
    "X_train_raw, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "X_val_raw, X_test_raw, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n",
    "\n",
    "# Sauvegarde CSV légère\n",
    "pd.DataFrame({'text': X_train_raw, 'label': y_train}).to_csv(\"splits/train.csv\", index=False)\n",
    "pd.DataFrame({'text': X_val_raw, 'label': y_val}).to_csv(\"splits/val.csv\", index=False)\n",
    "pd.DataFrame({'text': X_test_raw, 'label': y_test}).to_csv(\"splits/test.csv\", index=False)\n",
    "print(\"✅ Splits saved.\")\n",
    "\n",
    "# --- 3. PREPROCESSING HD ---\n",
    "print(\" Variable Transformation (TF-IDF HD)...\")\n",
    "\n",
    "# Modification Experte : 15k mots + Trigrammes\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=15000,\n",
    "    ngram_range=(1, 3),\n",
    "    stop_words='english'\n",
    ")\n",
    "\n",
    "X_train_vec = vectorizer.fit_transform(X_train_raw)\n",
    "X_val_vec = vectorizer.transform(X_val_raw)\n",
    "X_test_vec = vectorizer.transform(X_test_raw)\n",
    "\n",
    "joblib.dump(vectorizer, \"models/tfidf_vectorizer.pkl\")\n",
    "print(f\"✅ Vectorizer HD saved. Vocab size: {len(vectorizer.vocabulary_)}\")\n",
    "\n",
    "# --- 4. MULTI-MODEL TRAINING (Le Tournoi) ---\n",
    "models = {\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42),\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=N_ESTIMATORS, class_weight='balanced', random_state=42, n_jobs=-1),\n",
    "    \"MLP Classifier\": MLPClassifier(hidden_layer_sizes=(64, 32), max_iter=10, random_state=42, early_stopping=True)\n",
    "}\n",
    "\n",
    "metrics = {}\n",
    "\n",
    "print(\"\\n Starting Model Tournament...\")\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n==> Training {name}...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    model.fit(X_train_vec, y_train)\n",
    "    \n",
    "    # On évalue sur le Validation Set\n",
    "    y_pred_val = model.predict(X_val_vec)\n",
    "    \n",
    "    duration = time.time() - start_time\n",
    "    \n",
    "    metrics[name] = {\n",
    "        \"Val Accuracy\": accuracy_score(y_val, y_pred_val),\n",
    "        \"Val F1-Score\": f1_score(y_val, y_pred_val, average='weighted'),\n",
    "        \"Training Time (s)\": round(duration, 2)\n",
    "    }\n",
    "    # Sauvegarde de chaque modèle\n",
    "    joblib.dump(model, f\"models/{name.replace(' ', '_')}.pkl\")\n",
    "    print(f\"   -> F1-Score (Val): {metrics[name]['Val F1-Score']:.4f}\")\n",
    "\n",
    "# --- 5. RÉSULTATS ---\n",
    "metrics_df = pd.DataFrame(metrics).T\n",
    "print(\"\\n --- TOURNAMENT RESULTS --- \")\n",
    "print(metrics_df.sort_values(by=\"Val F1-Score\", ascending=False))\n",
    "\n",
    "# --- 6. VERDICT ---\n",
    "best_model_name = metrics_df[\"Val F1-Score\"].idxmax()\n",
    "print(f\"\\n Champion: {best_model_name}\")\n",
    "print(f\"✅ Phase 1 Completed successfully. Models are ready in 'models/' folder.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
